{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ckonlpy.tag import Twitter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_part(doc,stopword) :\n",
    "    doc = pd.read_csv(doc)\n",
    "    doc = list(doc[\"checked\"])\n",
    "    # doc = doc.split('\\n')\n",
    "    text = pd.read_csv(stopword)\n",
    "    text_list = list(np.array(text['불용어'].tolist()))\n",
    "    twitter = Twitter()\n",
    "    twitter.add_dictionary(['암묵지','창출','유즈 케이스','유즈케이스','내재화','해결','고려사항','장기적','단기적','사이언티스트','전처리','이상치','결측치','학습용 데이터','인공지능','텍스트 마이닝','메타버스','키워드','시사점','가속화','선도국','고품질','적극적','투자','불확실성','감소','중장기','장년층','노년층','상대적','최소화','디지털 리터러시 교육','세대별','맞춤형','어디서나','특성','긍정적','시공간'], 'Noun')\n",
    "    key_part = []\n",
    "    tokenized_nouns = []\n",
    "    tokenized_nouns_11 = []\n",
    "    result = []\n",
    "    candidates = []\n",
    "    # candidates_list = []\n",
    "    \n",
    "    for i in range(0,len(doc)) :\n",
    "        \n",
    "        key_part.append(twitter.pos(doc[i]))\n",
    "        tokenized_nouns.append(','.join([word[0] for word in key_part[i] if word[1] == 'Noun']))\n",
    "        tokenized_nouns_11.append([tokenized_nouns[i]])\n",
    "        result.append([word for word in tokenized_nouns_11[i] if not word in text_list])\n",
    "    \n",
    "        n_gram_range = (0, 3)\n",
    "        \n",
    "        count = CountVectorizer(ngram_range=n_gram_range).fit(result[i])\n",
    "        temp_ = list(count.get_feature_names_out())\n",
    "        candidates.append(temp_)\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(candidates)):\n",
    "        result += candidates[i]\n",
    "        \n",
    "    model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "    doc_embedding = model.encode([doc_2])\n",
    "    candidate_embeddings = model.encode(result)\n",
    "    \n",
    "    top_n = 5\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    keywords = [result[index] for index in distances.argsort()[0][-top_n:]]\n",
    "    \n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "\n",
    "# 각 키워드들 간의 유사도\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                        candidate_embeddings)\n",
    "\n",
    "# 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick.\n",
    "    words_idx = list(distances.argsort()[0][-30:])\n",
    "    words_vals = [result[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # 각 키워드들 중에서 가장 덜 유사한 키워드들간의 조합을 계산\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "                candidate = combination\n",
    "                min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "422bacecc5a04b4f9fe9b50f42372ce3b786ed202976d994abd71261280d25ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
